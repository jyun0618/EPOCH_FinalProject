{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JAsw0gN6rTDndXjeJ4H1vmmjtu7tLpjI",
      "authorship_tag": "ABX9TyPdKm7jQT/TtOLEzcaXC5Dh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyun0618/EPOCH_FinalProject/blob/main/modeling/Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhy-53-58ew8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
        "from sklearn.metrics import log_loss\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv('/content/drive/MyDrive/EPOCH/Final Project/X_train.csv')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/EPOCH/Final Project/y_train.csv')\n",
        "X_val = pd.read_csv('/content/drive/MyDrive/EPOCH/Final Project/X_val.csv')\n",
        "y_val = pd.read_csv('/content/drive/MyDrive/EPOCH/Final Project/y_val.csv')\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/EPOCH/Final Project/X_test.csv')\n",
        "\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/EPOCH/Final Project/data/sample_submission.csv')"
      ],
      "metadata": {
        "id": "5JH9WXjg9pdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 모델 학습"
      ],
      "metadata": {
        "id": "JNHZATv3-M_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 하이퍼파라미터 튜닝"
      ],
      "metadata": {
        "id": "ZcaMJz5E-PjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1. Random Forest Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "bxYUS88b-KV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "import joblib  # 모델 저장용 라이브러리\n",
        "\n",
        "# 모델 초기화\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# 하이퍼파라미터 범위 정의\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# GridSearchCV 설정\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_log_loss')\n",
        "\n",
        "# GridSearch 수행\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 테스트 데이터로 성능 평가\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict_proba(X_val)\n",
        "print(\"log loss score:\", log_loss(y_val, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# 모델 저장\n",
        "model_filename = 'best_randomforest_model.pkl'\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")\n",
        "\n",
        "# 모델 로드\n",
        "loaded_model = joblib.load('best_randomforest_model.pkl')\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# 로드한 모델로 테스트 데이터 예측\n",
        "loaded_y_pred_rf = loaded_model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "0PfokV6c-GmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. XGBoost Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "qeyjVlMJFHA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# XGBoost 모델 초기화\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# 하이퍼파라미터 범위 설정\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "# GridSearchCV 설정\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_log_loss',\n",
        "    cv=5,  # 5-fold 교차 검증\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# GridSearch 수행\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적 모델로 테스트 데이터 평가\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict_proba(X_val)\n",
        "logloss = log_loss(y_val, y_pred)\n",
        "print(\"log loss score:\", logloss)\n",
        "\n",
        "\n",
        "\n",
        "# 모델 저장\n",
        "model_filename = 'best_xgboost_model.pkl'\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"Model saved to {model_filename}\")\n",
        "\n",
        "# 모델 로드\n",
        "loaded_model = joblib.load(model_filename)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# 로드한 모델로 테스트 데이터 재평가\n",
        "loaded_y_pred_xg = loaded_model.predict_proba(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsQRxy9ZFFuu",
        "outputId": "fa007c9e-9c33-4bf2-a95b-9097fc92a4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01118921, 0.34227154, 0.6465393 ],\n",
              "       [0.04113001, 0.06600755, 0.89286244],\n",
              "       [0.02133671, 0.24997938, 0.72868395],\n",
              "       ...,\n",
              "       [0.02725354, 0.08757222, 0.8851743 ],\n",
              "       [0.02785655, 0.16385484, 0.80828863],\n",
              "       [0.0230907 , 0.28631285, 0.69059646]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출 파일 저장\n",
        "sample_submission.iloc[:,1:] = loaded_y_pred_xg\n",
        "sample_submission.to_csv('best_xgboost_model.csv', index=False)"
      ],
      "metadata": {
        "id": "a2J4CmKAtwfC",
        "outputId": "5cfc8ea5-3120-4fb2-bc91-4aa351451597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-44ad6ecc5737>:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.01118921 0.04113001 0.02133671 ... 0.02725354 0.02785655 0.0230907 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  sample_submission.iloc[:,1:] = loaded_y_pred_xg\n",
            "<ipython-input-21-44ad6ecc5737>:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.34227154 0.06600755 0.24997938 ... 0.08757222 0.16385484 0.28631285]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  sample_submission.iloc[:,1:] = loaded_y_pred_xg\n",
            "<ipython-input-21-44ad6ecc5737>:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.6465393  0.89286244 0.72868395 ... 0.8851743  0.80828863 0.69059646]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  sample_submission.iloc[:,1:] = loaded_y_pred_xg\n"
          ]
        }
      ]
    }
  ]
}